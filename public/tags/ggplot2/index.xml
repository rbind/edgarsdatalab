<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ggplot2 on Edgar&#39;s Data Lab</title>
    <link>/tags/ggplot2/</link>
    <description>Recent content in Ggplot2 on Edgar&#39;s Data Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/ggplot2/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sentiment analysis using tidytext</title>
      <link>/2017/09/04/sentiment-analysis-using-tidytext/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/04/sentiment-analysis-using-tidytext/</guid>
      <description>Quick introGetting familiar with the new tidytext package was a great weekend project. This example follows the structure of the Introduction to tidytext article by the authors of the package, Julia Silge and David Robinson.
The source of the text for this example are tweets. More specifically, tweets with the rstats hashtag. This project will also be an attempt to learn something about the community.
Twitter data importThe twitterR package opens the Twitter API to R users.</description>
    </item>
    
    <item>
      <title>[Infographic] 16 years of Banking Data…and beyond</title>
      <link>/2016/08/25/infographic-16-years-of-banking-dataand-beyond/</link>
      <pubDate>Thu, 25 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/08/25/infographic-16-years-of-banking-dataand-beyond/</guid>
      <description>Originaly published on LinkedIn, March 6 2016
 For the full size version click here
The Data – 1.5 million rows across 16 files were brought into the analysis. Each file contained a specific year and each row a specific branch.
The Math – For the forecasting, the model methodology used was ARIMA (Autoregressive Integrated Moving Average). This kind of model works well for time series analysis. To see the full R Markup report describing how each model was chosen click here.</description>
    </item>
    
    <item>
      <title>5 things I learned from open banking data</title>
      <link>/2016/08/24/5-things-i-learned-from-open-banking-data/</link>
      <pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/08/24/5-things-i-learned-from-open-banking-data/</guid>
      <description>Original published on LinkedIn, February 10 2016
Banks and other financial institutions submit to the FDIC a report of all of the money held for deposit at each of their branches. A compilation of the reports from each bank is available as a single dataset on the FDIC’s website.
Here are 5 insights from analyzing the most recent dataset:
In 2015, $10.6 trillion dollars in total deposits were reported – This was the first eye opener for me; this number is a 1 followed by 13 zeroes.</description>
    </item>
    
  </channel>
</rss>